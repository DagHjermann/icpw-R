---
title: "160_Time_series_results_James"
author: "DHJ"
date: "8 5 2020"
output: 
  html_document:
    toc: true    
    toc_float: true
    keep_md: true

---

**NOTE: this script has been 'abandoned'**   
* instead see script '160parm...' which is run using '160parm_run...', producing 160a, b and c 

Analysis of NO3 decrease, based on James' trend results    
* Taken from `https://github.com/JamesSample/icpw2/tree/master/thematic_report_2020/results`   
* Sen slope of NO3, TOTN, TOC/TON etc. 1992-2016
* Response variable in all analyses are *whether NO3 decreases or not*     
* Predictors:
    - slope_dep_vs_time: Trend in Tot-N deposition 1992-2016    
    - NO3, TOTN_dep: Medians of NO3, TOTN_dep (Tot-N deposition) 1992-2016   
    - TOC: Medians of TOC 1992-2016 (section 5 and 6 only)     
    - pre, tmp: mean precipitation + temp   
    - catchment_area (section 5 only)   
    - Land cover   
* Basically 3 sets of identical analyses (5,6,7) which only differ in data set (5 has the largest set of variables and the lowest sample size)   


## 1. Libraries  
```{r, results='hide', message=FALSE, warning=FALSE}

# All of these packages cn be loaded at once using library(tidyverse). (I just like to be specific.)
library(dplyr)
library(tidyr)
library(purrr)
library(lubridate)
library(ggplot2)

# Too many packages, not all are used
# library(forcats)
# library(mgcv)
# library(nlme)
library(mapview)
library(visreg)     # visreg
library(rkt)        # Theil -Sen Regression

library(MuMIn)      

# Trees and forests
# install.packages("party")
# install.packages("modeltools")
# install.packages("coin")
# install.packages("multcomp")
# install.packages("TH.data")
library(party)
# install.packages("evtree")
library(evtree)
# install.packages("randomForest")
library(randomForest)
library(randomForestExplainer)
library(pdp)

library(maps)
my_map <- map_data("world")

library(effects)    # handles lme models  
library(readxl)

knitr::opts_chunk$set(results = 'hold')
knitr::opts_chunk$set(warning = FALSE)

```

```{r}

# run_randomForestExplainer <- TRUE
run_randomForestExplainer <- FALSE

```



## 2. Data
```{r}

dat_annual_sel <- readRDS("Data/120_dat_annual_sel.rds")
# ts_model_list <- readRDS("Data/120_ts_model_list_linear.rds")
# ts_model_list_wout_TOC <- readRDS("Data/120_ts_model_list_wout_TOC.rds")

df_stations <- readRDS("Data/100_Stations.rds")
df_deposition <- readRDS("Data/100_Deposition.rds")
df_climate <- readRDS("Data/100_Climate.rds")

```

### Station metadata
```{r}

df_station <- read_excel(
  "K:/Prosjekter/langtransporterte forurensninger/O-23300 - ICP-WATERS - HWI/Faglige rapporter/2020 report/Land cover/ICPW_All_Stations_2020_2020_05_04.xlsx") %>%
  mutate(station_id = as.character(station_id))

```

### James' trends and medians     
```{r}

#
# Regression results
#
folder <- "https://github.com/JamesSample/icpw2/raw/master/thematic_report_2020/results/trends_1992-2016_no3"
file <- "trends_1992-2016_no3_results.csv"
fn <- paste0(folder, "/", file)

reg_no3 <- read.csv(fn, encoding = "UTF-8")
cat("Regression results:", sQuote(file), ",n =", nrow(reg_no3), "\n\n")

# Station metadata
file <- "trends_1992-2016_no3_stations.csv"
fn <- paste0(folder, "/", file)

reg_no3_st <- read.csv(fn, encoding = "UTF-8")
cat("Regression result metadata:", sQuote(file), ",n =", nrow(reg_no3_st), "\n\n")

cat("Countries with trends: \n")
xtabs(~country, reg_no3_st)  

#
# Medians NO3
#

if (FALSE){

  # OLD: 2012-2016 medians NO3  

  cat("--------------------------------------------------------------------------\n")
  folder <- "https://github.com/JamesSample/icpw2/raw/master/thematic_report_2020/results/medians_2012-2016"
  file <- "medians_2012-2016_no3.csv"
  fn <- paste0(folder, "/", file)
  # data:
  medians_no3 <- read.csv(fn, encoding = "UTF-8")
  cat("Medians NO3:", sQuote(file), ",n =", nrow(medians_no3), "\n\n")
  file <- "medians_2012-2016_no3_stations.csv"
  fn <- paste0(folder, "/", file)
  # metadata:
  medians_no3_st <- read.csv(fn, encoding = "UTF-8")
  cat("Median metadata (not used):", sQuote(file), "n =", nrow(medians_no3_st), "\n\n")
  # stats:
  cat("Countries with medians: \n")
  xtabs(~country, medians_no3_st)  
  
  #
  #  OLD: 2012-2016 Medians TOC
  #
  cat("--------------------------------------------------------------------------\n")
  
  file <- "medians_2012-2016_toc_totn_no3_nh4.csv"
  fn <- paste0(folder, "/", file)
  
  medians_toc <- read.csv(fn, encoding = "UTF-8")
  cat("Medians TOC:", sQuote(file), ",n =", nrow(medians_toc), "\n\n")
  
  cat("Countries with medians: \n")
  xtabs(~country, medians_no3_st)  
  
}


```
### Start 'dat'  
With slope regression data  
* Make one line per station  
```{r}

# table(reg_no3$variable)

# Slope 
df1 <- reg_no3 %>%
  filter(variable %in% c("NO3-N_µg/l N", "TOC/TON")) %>%
  select(station_id, variable, sen_slp) %>%
  tidyr::pivot_wider(names_from = "variable", values_from = "sen_slp") %>%
  rename(slope_no3_vs_time = `NO3-N_µg/l N`, 
         slope_tocton_vs_time = `TOC/TON`)
  
# Slope p-value
df2 <- reg_no3 %>%
  filter(variable %in% c("NO3-N_µg/l N", "TOC/TON")) %>%
  select(station_id, variable, mk_p_val) %>%
  tidyr::pivot_wider(names_from = "variable", values_from = "mk_p_val") %>%
  rename(p_no3_vs_time = `NO3-N_µg/l N`, 
         p_tocton_vs_time = `TOC/TON`)

# Medians
df3 <- reg_no3 %>%
  filter(variable %in% c("NO3-N_µg/l N", "TOC_mg C/l")) %>%
  select(station_id, variable, median) %>%
  tidyr::pivot_wider(names_from = "variable", values_from = "median") %>%
  rename(NO3 = `NO3-N_µg/l N`, 
         TOC = `TOC_mg C/l`)

cat("\n")
cat("df1, n =", nrow(df1), "\n")
cat("df2, n =", nrow(df2), "\n")
cat("df3, n =", nrow(df3), "\n")

dat <- df1 %>%
  full_join(df2, by = "station_id") %>%
  full_join(df3, by = "station_id")

cat("dat, n =", nrow(dat), "\n")

```

```{r, echo = FALSE}

# ### Deposition OLD    
# * Data from K or github 
# * calculate regression (Theil-Senslope 1992-2016)  
# * calculate medians (2012-2016)

if (FALSE){
  
  ### version 1: Get deposition (annual) from K     
  # df_deposition <- readRDS("Data/100_Deposition.rds") %>%
  #   as.data.frame()
  
  ### version 2: Get deposition (annual) from github     
  fn <- "https://github.com/JamesSample/icpw2/raw/master/deposition_data/csv/icpw_totn_dep_1990-2016_all_stns.csv"
  df_deposition <- read.csv(fn) %>%
    tidyr::pivot_longer(-station_id,
                        names_to = "year", names_prefix = "X", names_transform = list(year = as.numeric),
                        values_to = "TOTN_dep")
  
  cat("n =", nrow(df_deposition), "\n")
  cat("range =", range(df_deposition$year), "\n")
  
  df_deposition <- df_deposition %>%
    filter(year %in% 1992:2016)
  
  cat("\nNumber of years per station: \n")
  df_deposition %>%
    count(station_id) %>%
    xtabs(~n, .)  
  cat("\n")
  
  # test Senslope function
  # df_test <- df_deposition %>% filter(station_id == 38115)
  # result <- rkt(df_test$year, df_test$TOTN_dep)
  # data.frame(station_id = 38115, TOTN_dep_P = result$sl, TOTN_dep_slope = result$B)
  
  # Function for Sen slope
  get_senslope <- function(data){
    result <- rkt(data$year, data$TOTN_dep)
    data.frame(station_id = data$station_id[1], slope_dep_vs_time = result$B, p_dep_vs_time = result$sl)
  }
  
  df_deposition_slope <- df_deposition %>%
    split(.$station_id) %>% # str()
    purrr::map_dfr(get_senslope)  
  cat("Slope: n =", nrow(df_deposition_slope), "\n")
  
  
  df_deposition_median <- df_deposition %>%
    filter(year %in% 2012:2016) %>%
    group_by(station_id) %>%
    summarise(TOTN_dep = median(TOTN_dep))  
  cat("Median: n =", nrow(df_deposition_median), "\n")
  
}

```
### Deposition trends and median 1992-2006     
```{r}

fn <- "https://github.com/JamesSample/icpw2/raw/master/thematic_report_2020/results/deposition/totn_dep_trends_icpw_stns.csv"  

df_deposition <- read.csv(fn) %>% 
  filter(variable == "totn_mgNpm2")  

cat("n =", nrow(df_deposition), "\n")

```

### Add deposition slope and medians to data  
```{r}

cat("dat, n =", nrow(dat), "\n")

dat <- dat %>% 
  left_join(df_deposition %>% 
              select(station_id, median, sen_slp, mk_p_val) %>%
              rename(TOTN_dep = median,
                     slope_dep_vs_time = sen_slp,
                     p_dep_vs_time = mk_p_val),
                 by = "station_id")

cat("dat, n =", nrow(dat), "\n")

# names(dat)

```
### Add medians and station metadata   
```{r}

dat <- dat %>%
  left_join(reg_no3_st, by = "station_id")

cat("dat, n =", nrow(dat), "\n")

# Simplify names by removing units
# names(dat)
# names(dat) <- sub(".N_µg.l.N", "", names(dat))
# names(dat) <- sub("_mg.C.l", "", names(dat))
# names(dat) <- sub("_µg.l.P", "", names(dat))

cat("\nVariable names: \n")
names(dat)


```

### Add climate and deposition means 
```{r}

df_climate <- readRDS("Data/100_Climate.rds") %>%
  filter(year %in% 1992:2006)

df_climate_mean <- df_climate %>%
  group_by(station_id, variable) %>% 
  summarise(mean = mean(value), .groups = "drop") %>%
  tidyr::pivot_wider(names_from = "variable", values_from = "mean")

# Add
dat <- dat %>%
  left_join(df_climate_mean, by = "station_id")

cat("dat, n =", nrow(dat), "\n")

```

### Add land cover    
* Combine: bare_sparse = bare_rock + sparsely_vegetated + glacier   
* Select: coniferous, deciduous, lake, mixed_forest, wetland, bare_sparse   
```{r}

fn <- "K:/Prosjekter/langtransporterte forurensninger/O-23300 - ICP-WATERS - HWI/Faglige rapporter/2020 report/Land cover/ICPW_All_Stations_2020_2020_05_04.xlsx"

df_station <- read_excel(fn) %>%
  mutate(bare_sparse = bare_rock + sparsely_vegetated + glacier,
         decid_mixed = deciduous + mixed_forest,
         lake_water = lake + water_ex_lake)

nrow(dat)
dat <- left_join(dat, 
                 df_station %>% select(-(station_code:longitude), -(altitude:region)), 
                 by = "station_id"
)

nrow(dat)
names(dat) %>% paste(collapse = " + ") 

```

```{r, echo = FALSE}

### Check other land cover files  

if (FALSE){
  
  df1 <- read_excel(fn)
  nrow(df1)
  
  fn <- "K:/Prosjekter/langtransporterte forurensninger/O-23300 - ICP-WATERS - HWI/Faglige rapporter/2020 report/Land cover/all_icpw_sites_may_2020.xlsx" 
  
  df2 <- read_excel(fn)
  nrow(df2)
  
  fn <- "K:/Prosjekter/langtransporterte forurensninger/O-23300 - ICP-WATERS - HWI/Faglige rapporter/2020 report/Land cover/ICPW_All_Stations_2020_land cover_2020_05_04.xlsx"
  
  df3 <- read_excel(fn)
  nrow(df3)
  
  names(df1)
  names(df2)
  names(df3)
  
  names(df1) == names(df3)
  apply(is.na(df1), 2, sum) == apply(is.na(df3), 2, sum)
  
  for (i in 1:19)
    cat(i, ":", mean(df1[[i]] != df3[[i]], na.rm = TRUE), "\n")
  
}

```


## 3. Plot estimates  

Note: **No USA**

```{r, fig.width=9, fig.height=7}

ggplot(dat, aes(slope_dep_vs_time, slope_no3_vs_time)) + 
  geom_point(data = dat %>% filter(p_no3_vs_time < 0.05), size = rel(2)) +
  geom_point(aes(color = country)) +
  geom_hline(yintercept = 0, linetype = 2) + 
  geom_vline(xintercept = 0, linetype = 2) 
  
ggplot(dat, aes(slope_dep_vs_time, slope_no3_vs_time,
                color = (p_no3_vs_time < 0.05))) + 
  geom_point() +
  facet_wrap(vars(country)) +
  geom_hline(yintercept = 0, linetype = 2) + 
  geom_vline(xintercept = 0, linetype = 2) + 
  labs(title = "A selection of countries")

dat %>%
  filter(!country %in% c("Latvia","Ireland","Italy","Netherlands")) %>%
  ggplot(aes(slope_dep_vs_time, slope_no3_vs_time,
             color = (p_no3_vs_time < 0.05))) + 
  geom_point() +
  facet_wrap(vars(country)) +
  geom_hline(yintercept = 0, linetype = 2) + 
  geom_vline(xintercept = 0, linetype = 2) + 
  labs(title = "A selection of countries") + 
  ylim(-50, 25)


```


## 4. Analysis of 'Significant / non-significant NO3 decline'   
* Parts 5, 6 and 7 all run logistic regression + "trees and forest" methods  
* Each part differ only in dataset used  

## 5a. Data INCLUDING catchment_area    
```{r}

# Data for analyses
df_analysis <- dat %>%
  mutate(
    no3_decline = case_when(
      slope_no3_vs_time < 0 & p_no3_vs_time <= 0.05 ~ 1,
      TRUE ~ 0)
  ) %>%
  select(no3_decline, slope_dep_vs_time,
         NO3, TOC, TOTN_dep,
         latitude, longitude, altitude,
         pre, tmp, catchment_area,
         urban, cultivated, 
         coniferous, decid_mixed, 
         total_shrub_herbaceous, 
         wetland, lake_water, 
         bare_sparse)

# names(dat) %>% paste(collapse = ", ")

cat("Number of missing values per variable: \n")
apply(is.na(df_analysis), 2, sum) 
cat("\n")

# What is missing? (long output)
if (FALSE){
dat %>% 
  split(.$country) %>%
  purrr::map(~apply(is.na(.), 2, mean))
}

cat("Number of complete observations: \n")
complete <- complete.cases(df_analysis)
table(complete)

cat("\n\n")
cat("Number of complete observations by country: \n")
table(dat$country, complete)

# Keep only complete cases
df_analysis <- df_analysis[complete.cases(df_analysis),]

cat("\n\n")
cat("Original data: n =", nrow(dat), "\n")
cat("Analysis: n =", nrow(df_analysis), "\n")


```







## 5b. Tree and forest classification


### Split into training and validation data
```{r}

set.seed(123)

x <- runif(nrow(df_analysis))
train <- ifelse(x < 0.9, TRUE, FALSE)

train_set <- df_analysis[train,]  %>% 
  mutate(no3_decline_f = factor(no3_decline)) %>% select(-no3_decline, -longitude, - latitude) %>%
  as.data.frame()
valid_set <- df_analysis[!train,] %>% 
  mutate(no3_decline_f = factor(no3_decline)) %>% select(-no3_decline, -longitude, - latitude) %>%
  as.data.frame()

```


### a. Tree classification using 'party'   
```{r, fig.width=8, fig.height=8}

(ct = ctree(no3_decline_f ~ ., data = train_set))

plot(ct, main="Conditional Inference Tree")

cat("\n\n")
cat("Table of prediction errors \n")
table(predict(ct), train_set$no3_decline_f)
cat("\n\n")

cat("Classification of training set \n")
tr.pred = predict(ct, newdata = valid_set, type="prob")
colnames(tr.pred) <- c("P0", "P1")
# tr.pred <- tr.pred %>% map_dfr(~data.frame(P0 = .[1], P1 = .[2]))
table(tr.pred[,"P1"] > 0.5, valid_set$no3_decline_f)


```

### b. Evtree (Evolutionary Learning)   
```{r, fig.width=8, fig.height=8}

ev.raw = evtree(no3_decline_f ~ ., data = train_set)

plot(ev.raw)
cat("Predicted in training data: \n")
table(predict(ev.raw), train_set$no3_decline_f)

cat("\n\nPrediction errors in training data: \n")
1-mean(predict(ev.raw) == train_set$no3_decline_f)
```


### c. Random forest  
* *For results/interpretation, see separate document '160_randomforest_James_data.html'*  
* Model called 'model1'
```{r}

model1 <- randomForest(no3_decline_f ~ ., 
                       data = train_set, 
                       mtry = 5,
                       importance = TRUE)

model1

```


#### Random forest, predict on training data
```{r}

# Predicting on train set
pred_valid <- predict(model1, valid_set, type = "class")
# Checking classification accuracy
table(pred_valid, valid_set$no3_decline_f)  

```

#### Random forest, importance of variables
```{r}

# Calculation
importance <- measure_importance(model1)

```

```{r}

plot_multi_way_importance(importance, size_measure = "no_of_nodes", no_of_labels = 12)  
plot_multi_way_importance(importance, x_measure = "accuracy_decrease", y_measure = "gini_decrease", 
                          size_measure = "p_value", no_of_labels = 12)

```

#### Random forest, show partial effects  

```{r, warning=FALSE, message=FALSE, results='hide'}

variables_for_plot <- importance %>%
  mutate(variable = levels(variable)[as.numeric(variable)]) %>%
  arrange(desc(gini_decrease)) %>%
  pull(variable) %>%
  head(12)


# Caclulation
plotdata <- NULL  # will be list for storing results

for (i in 1:6){
  varno1 <- c(1,3,5,7,9,11)[i]
  varno2 <- varno1 + 1
  plotdata[[i]] <- model1 %>%
    partial(pred.var = variables_for_plot[c(varno1, varno2)], chull = TRUE, progress = "text", 
            which.class = "1", prob = TRUE) 
}

```


```{r, warning=FALSE}

for (i in 1:6){
    autoplot(plotdata[[i]], contour = TRUE, legend.title = "Probability\nNO3 decline") %>%
    print()
}

```


## 5c. Logistic regression, exclude coordinates    
```{r, results  = "hold"}

fm <- glm(
  no3_decline ~ catchment_area + TOC + 
    altitude + decid_mixed + slope_dep_vs_time + 
    TOC + NO3 + TOTN_dep + catchment_area + coniferous +
    tmp + lake_water + wetland,
  data = df_analysis, 
  family = "binomial",
  na.action = "na.fail")

dd1b <- dredge(fm)                       # only once
saveRDS(dd1b, "Data/160_all_dd1b.rds")    # save it as it takes a couple of minutes
# dd1b <- readRDS("Data/160_all_dd1b.rds")

# subset(dd1b, delta < 1)
subset(dd1b, delta < 2)

cat("\n\nR2: \n")
dd1b_mod1 <- get.models(dd1b, 1)[[1]]  
# summary(dd1b_mod1)  

par(mfrow = c(2,3), mar = c(4,5,2,1), oma = c(0,0,2,0))
visreg(dd1b_mod1, scale = "response")

```



## 6a. Data EXCLUDING catchment_area   
* Includes USA data, still missing UK and most German data      
*  Germany is missing TOC and NO3 (87%), UK is missing land cover (100%)
```{r}

# Data for analyses
df_analysis <- dat %>%
  mutate(
    no3_decline = case_when(
      slope_no3_vs_time < 0 & p_no3_vs_time <= 0.05 ~ 1,
      TRUE ~ 0)
  ) %>%
  select(country, no3_decline, slope_dep_vs_time,
         NO3, TOC, TOTN_dep,
         latitude, longitude, altitude, 
         pre, tmp, 
         urban, cultivated, deciduous, coniferous, mixed_forest, total_shrub_herbaceous, 
         wetland, lake, bare_sparse)
  
  

cat("Number of missing values per variable: \n")
apply(is.na(df_analysis), 2, sum) 
cat("\n")

# What is missing? (long output)
if (FALSE){
  df <- df_analysis %>% 
    mutate(country = substr(country, 1, 3)) %>%
    split(.$country) %>%
    purrr::map_dfr(~apply(is.na(.), 2, mean) %>% round(2), .id = "Country")
  names(df) <- substr(names(df), 1, 9)
  df
  
}

cat("Number of complete observations: \n")
complete <- complete.cases(df_analysis)
table(complete)

cat("\n\n")
cat("Number of complete observations by country: \n")
table(dat$country, complete)

# Keep only complete cases
df_analysis <- df_analysis[complete.cases(df_analysis),] %>%
  select(-country)

cat("\n\n")
cat("Original data: n =", nrow(dat), "\n")
cat("Analysis: n =", nrow(df_analysis), "\n")



```




## 6b. Tree and forest classification


### Split into training and validation data
```{r}

set.seed(123)

x <- runif(nrow(df_analysis))
train <- ifelse(x < 0.9, TRUE, FALSE)

train_set <- df_analysis[train,]  %>% 
  mutate(no3_decline_f = factor(no3_decline)) %>% select(-no3_decline, -longitude, - latitude) %>%
  as.data.frame()
valid_set <- df_analysis[!train,] %>% 
  mutate(no3_decline_f = factor(no3_decline)) %>% select(-no3_decline, -longitude, - latitude) %>%
  as.data.frame()

```


### a. Tree classification using 'party'   
```{r, fig.width=8, fig.height=8}

(ct = ctree(no3_decline_f ~ ., data = train_set))

plot(ct, main="Conditional Inference Tree")

cat("\n\n")
cat("Table of prediction errors \n")
table(predict(ct), train_set$no3_decline_f)
cat("\n\n")

cat("Classification of training set \n")
tr.pred = predict(ct, newdata = valid_set, type="prob")
colnames(tr.pred) <- c("P0", "P1")
# tr.pred <- tr.pred %>% map_dfr(~data.frame(P0 = .[1], P1 = .[2]))
table(tr.pred[,"P1"] > 0.5, valid_set$no3_decline_f)


```

### b. Evtree (Evolutionary Learning)   
```{r, fig.width=10, fig.height=8}

ev.raw = evtree(no3_decline_f ~ ., data = train_set)

plot(ev.raw)
cat("Predicted in training data: \n")
table(predict(ev.raw), train_set$no3_decline_f)

cat("\n\nPrediction errors in training data: \n")
1-mean(predict(ev.raw) == train_set$no3_decline_f)

```


### c. Random forest  
* *For results/interpretation, see separate document '160_randomforest_James_data.html'*  
* Model called 'model2'
```{r}

model2 <- randomForest(no3_decline_f ~ ., 
                       data = train_set, 
                       mtry = 5,
                       importance = TRUE)

model2

```


#### Random forest, predict on training data
```{r}

# Predicting on train set
pred_valid <- predict(model2, valid_set, type = "class")
# Checking classification accuracy
table(pred_valid, valid_set$no3_decline_f)  

```


#### Random forest, importance of variables
```{r}

# Calculation
importance <- measure_importance(model2)

```

```{r}

plot_multi_way_importance(importance, size_measure = "no_of_nodes", no_of_labels = 12)  
plot_multi_way_importance(importance, x_measure = "accuracy_decrease", y_measure = "gini_decrease", 
                          size_measure = "p_value", no_of_labels = 12)

```

#### Random forest, show partial effects  

```{r, warning=FALSE, message=FALSE, results='hide'}

variables_for_plot <- importance %>%
  mutate(variable = levels(variable)[as.numeric(variable)]) %>%
  arrange(desc(gini_decrease)) %>%
  pull(variable) %>%
  head(12)

# Caclulation
plotdata <- NULL  # will be list for storing results

for (i in 1:6){
  varno1 <- c(1,3,5,7,9,11)[i]
  varno2 <- varno1 + 1
  plotdata[[i]] <- model2 %>%
    partial(pred.var = variables_for_plot[c(varno1, varno2)], chull = TRUE, progress = "text", 
            which.class = "1", prob = TRUE) 
}

```


```{r, warning=FALSE}

for (i in 1:6){
    autoplot(plotdata[[i]], contour = TRUE, legend.title = "Probability\nNO3 decline") %>%
    print()
}

```


## 6c. Logistic regression, exclude coordinates    
```{r, results  = "hold"}

fm <- glm(
  no3_decline ~ TOC + 
    altitude + decid_mixed + slope_dep_vs_time + 
    TOC + NO3 + TOTN_dep + catchment_area + coniferous +
    tmp + lake_water + wetland,
  data = df_analysis, 
  family = "binomial",
  na.action = "na.fail")

dd2b <- dredge(fm)                       # only once
saveRDS(dd2b, "Data/160_all_dd2b.rds")    # save it as it takes a couple of minutes
# dd2b <- readRDS("Data/160_all_dd2b.rds")

# subset(dd2b, delta < 1)
subset(dd2b, delta < 2)

cat("\n\nR2: \n")
dd2b_mod1 <- get.models(dd2b, 1)[[1]]  
# summary(dd2b_mod1)  

par(mfrow = c(2,3), mar = c(4,5,2,1), oma = c(0,0,2,0))
visreg(dd2b_mod1, scale = "response")

```


## 7a. Data EXCLUDING catchment_area and TOC    
* Includes USA data, still missing Estonia (missing altitude) and UK (mising land cover)      
*  Germany is missing TOC (87%), UK is missing land cover (100%)
```{r}

# Data for analyses
df_analysis <- dat %>%
  mutate(
    no3_decline = case_when(
      slope_no3_vs_time < 0 & p_no3_vs_time <= 0.05 ~ 1,
      TRUE ~ 0)
  ) %>%
  select(country,
         no3_decline, slope_dep_vs_time, 
         TOTN_dep, NO3,
         latitude, longitude, altitude, 
         pre, tmp, 
         urban, cultivated, deciduous, coniferous, mixed_forest, total_shrub_herbaceous, 
         wetland, lake, bare_sparse)


cat("Number of missing values per variable: \n")
apply(is.na(df_analysis), 2, sum) 
cat("\n")

# What is missing? (long output)
if (FALSE){
  df <- df_analysis %>% 
    mutate(country = substr(country, 1, 8)) %>%
    split(.$country) %>%
    purrr::map_dfr(~apply(is.na(.), 2, mean) %>% round(2), .id = "Country")
  names(df) <- substr(names(df), 1, 9)
  df
}

cat("Number of complete observations: \n")
complete <- complete.cases(df_analysis)
table(complete)

cat("\n\n")
cat("Number of complete observations by country: \n")
table(dat$country, complete)

# Keep only complete cases
df_analysis <- df_analysis[complete.cases(df_analysis),] %>%
  select(-country)

cat("\n\n")
cat("Original data: n =", nrow(dat), "\n")
cat("Analysis: n =", nrow(df_analysis), "\n")



```



## 7b. Tree and forest classification


### Split into training and validation data   
```{r}

set.seed(123)

x <- runif(nrow(df_analysis))
train <- ifelse(x < 0.9, TRUE, FALSE)

train_set <- df_analysis[train,]  %>% 
  mutate(no3_decline_f = factor(no3_decline)) %>% select(-no3_decline, -longitude, - latitude) %>%
  as.data.frame()
valid_set <- df_analysis[!train,] %>% 
  mutate(no3_decline_f = factor(no3_decline)) %>% select(-no3_decline, -longitude, - latitude) %>%
  as.data.frame()

```


### a. Tree classification using 'party'   
```{r, fig.width=8, fig.height=8}

(ct = ctree(no3_decline_f ~ ., data = train_set))

plot(ct, main="Conditional Inference Tree")

cat("\n\n")
cat("Table of prediction errors \n")
table(predict(ct), train_set$no3_decline_f)
cat("\n\n")

cat("Classification of training set \n")
tr.pred = predict(ct, newdata = valid_set, type="prob")
colnames(tr.pred) <- c("P0", "P1")
# tr.pred <- tr.pred %>% map_dfr(~data.frame(P0 = .[1], P1 = .[2]))
table(tr.pred[,"P1"] > 0.5, valid_set$no3_decline_f)


```

### b. Evtree (Evolutionary Learning)   
```{r, fig.width=10, fig.height=8}

ev.raw = evtree(no3_decline_f ~ ., data = train_set)

plot(ev.raw)
cat("Predicted in training data: \n")
table(predict(ev.raw), train_set$no3_decline_f)

cat("\n\nPrediction errors in training data: \n")
1-mean(predict(ev.raw) == train_set$no3_decline_f)

```


### c. Random forest  
* *For results/interpretation, see separate document '160_randomforest_James_data.html'*  
* Model called 'model3'
```{r}

model3 <- randomForest(no3_decline_f ~ ., 
                       data = train_set, 
                       mtry = 5,
                       importance = TRUE)

model3

```


#### Random forest, predict on training data
```{r}

# Predicting on train set
pred_valid <- predict(model3, valid_set, type = "class")
# Checking classification accuracy
table(pred_valid, valid_set$no3_decline_f)  

```

#### Random forest, importance of variables
```{r}

# Calculation
importance <- measure_importance(model3)

```

```{r}

plot_multi_way_importance(importance, size_measure = "no_of_nodes", no_of_labels = 12)  
plot_multi_way_importance(importance, x_measure = "accuracy_decrease", y_measure = "gini_decrease", 
                          size_measure = "p_value", no_of_labels = 12)

```

#### Random forest, show partial effects  

```{r, warning=FALSE, message=FALSE, results='hide'}

variables_for_plot <- importance %>%
  mutate(variable = levels(variable)[as.numeric(variable)]) %>%
  arrange(desc(gini_decrease)) %>%
  pull(variable) %>%
  head(12)

# Caclulation
plotdata <- NULL  # will be list for storing results

for (i in 1:6){
  varno1 <- c(1,3,5,7,9,11)[i]
  varno2 <- varno1 + 1
  plotdata[[i]] <- model3 %>%
    partial(pred.var = variables_for_plot[c(varno1, varno2)], chull = TRUE, progress = "text", 
            which.class = "1", prob = TRUE) 
}

```

```{r, warning=FALSE}

# Plot
for (i in 1:6){
    autoplot(plotdata[[i]], contour = TRUE, legend.title = "Probability\nNO3 decline") %>%
    print()
}

```

## 7c. Logistic regression, exclude coordinates    
```{r, results  = "hold"}

fm <- glm(
  no3_decline ~ altitude + decid_mixed + slope_dep_vs_time + 
    TOC + NO3 + TOTN_dep + catchment_area + coniferous +
    tmp + lake_water + wetland,
  data = df_analysis, 
  family = "binomial",
  na.action = "na.fail")

dd3b <- dredge(fm)                       # only once
saveRDS(dd3b, "Data/160_all_dd3b.rds")    # save it as it takes a couple of minutes
# dd3b <- readRDS("Data/160_all_dd3b.rds")

# subset(dd3b, delta < 1)
subset(dd3b, delta < 2)

cat("\n\nR2: \n")
dd3b_mod1 <- get.models(dd3b, 1)[[1]]  
# summary(dd3b_mod1)  

par(mfrow = c(2,3), mar = c(4,5,2,1), oma = c(0,0,2,0))
visreg(dd3b_mod1, scale = "response")

```

